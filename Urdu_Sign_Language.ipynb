{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c82a7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a457e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\d\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\d\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ba840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in c:\\users\\d\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: ffmpeg-python in c:\\users\\d\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\d\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: torch in c:\\users\\d\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\d\\anaconda3\\lib\\site-packages (from opencv-python-headless) (1.24.3)\n",
      "Requirement already satisfied: future in c:\\users\\d\\anaconda3\\lib\\site-packages (from ffmpeg-python) (0.18.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\d\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\d\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\d\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\d\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\d\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\d\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\d\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\d\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\d\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\d\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\d\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\d\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\d\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\d\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\d\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless ffmpeg-python tensorflow torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4634a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Extracts frames from a given video file. \n",
    "    Returns:\n",
    "        A list of frames resized to the target size.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        resized_frame = cv2.resize(frame, target_size)\n",
    "        # Normalize pixel values to be between 0 and 1\n",
    "        normalized_frame = resized_frame / 255.0\n",
    "        frames.append(normalized_frame)\n",
    "    cap.release()\n",
    "    return frames\n",
    "video_path = r'C:\\Users\\aqsa\\Downloads\\WORDS\\urdu.mov'\n",
    "frames = extract_frames(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r'C:\\Users\\aqsa\\Downloads\\WORDS\\urdu.mov')\n",
    "ret, frame = cap.read()  \n",
    "\n",
    "if ret:\n",
    "\n",
    "    resized_frame = cv2.resize(frame, (224, 224))\n",
    "    if resized_frame.shape == (224, 224, 3):\n",
    "        print(\"Frame size and channels are correct.\")\n",
    "    else:\n",
    "        print(\"Frame size or channels are incorrect.\")\n",
    "else:\n",
    "    print(\"Failed to read frame from the video.\")\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe32df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "impo\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    processed_frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        resized_frame = cv2.resize(frame, (224, 224))\n",
    "        processed_frames.append(resized_frame)\n",
    "    cap.release()\n",
    "    return np.array(processed_frames)\n",
    "\n",
    "# Assuming you have a video file\n",
    "processed_video = process_video('path/to/your/video.mov')\n",
    "\n",
    "# After processing, check if you have frames and their shape\n",
    "if processed_video.size > 0:\n",
    "    print(\"Processed video shape:\", processed_video.shape)\n",
    "    # Assuming you want to check if each frame is 224x224x3\n",
    "    if processed_video.shape[1:] == (224, 224, 3):\n",
    "        print(\"Each frame in the processed video has the correct shape.\")\n",
    "    else:\n",
    "        print(f\"Frames have incorrect shape: {processed_video.shape[1:]}\")\n",
    "else:\n",
    "    print(\"No frames were processed. Check your video path or the video content.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder_name in os.listdir(urdu_dir_path):\n",
    "    print(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7facdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "u38_directory_path = r'C:\\Users\\aqsa\\Downloads\\WORDS\\urdu\\U38'\n",
    "u38_files = os.listdir(u38_directory_path)\n",
    "print(u38_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678677ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_directory = glob(r\"C:\\Users\\aqsa\\Downloads\\WORDS\\urdu\\*\")\n",
    "print(files_in_directory)\n",
    "files_in_directory = os.listdir(r\"C:\\Users\\aqsa\\Downloads\\WORDS\\urdu\")\n",
    "print(files_in_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a7a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory_path = r'C:\\Users\\aqsa\\Downloads\\WORDS\\urdu'\n",
    "subdirectories = [aqsa for aqsa in os.listdir(base_directory_path) if os.path.isdir(os.path.join(base_directory_path, aqsa))]\n",
    "label_mapping = {name: idx for idx, name in enumerate(subdirectories)}\n",
    "data = []\n",
    "for subdir_name in subdirectories:\n",
    "    subdir_path = os.path.join(base_directory_path, subdir_name)\n",
    "    for file in os.listdir(subdir_path):\n",
    "        if file.endswith('.mov') or file.endswith('.mp4'):\n",
    "            frames_subfolder_path = os.path.join(subdir_path, 'extracted_frames') \n",
    "            if os.path.exists(frames_subfolder_path):\n",
    "                for frame_file in os.listdir(frames_subfolder_path):\n",
    "                    if frame_file.endswith('.jpg'): \n",
    "                        frame_path = os.path.join(frames_subfolder_path, frame_file)\n",
    "                        data.append((frame_path, label_mapping[subdir_name]))\n",
    "for frame_path, label in data:\n",
    "    print(f\"Frame: {frame_path}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ae648",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory_path = r'C:\\Users\\aqsa\\Downloads\\WORDS\\urdu'\n",
    "subdirectories = [aqsa for aqsa in os.listdir(base_directory_path) if os.path.isdir(os.path.join(base_directory_path, aqsa))]\n",
    "label_mapping = {name: idx for idx, name in enumerate(subdirectories)}\n",
    "data = []\n",
    "for subdir_name in subdirectories:\n",
    "    subdir_path = os.path.join(base_directory_path, subdir_name)\n",
    "    frames_subfolder_path = os.path.join(subdir_path, 'extracted_frames') \n",
    "    if os.path.exists(frames_subfolder_path):\n",
    "        for frame_file in os.listdir(frames_subfolder_path):\n",
    "            if frame_file.endswith('.jpg'): \n",
    "                frame_path = os.path.join(frames_subfolder_path, frame_file)\n",
    "                data.append((frame_path, label_mapping[subdir_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295660e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for frame_path, label in data:\n",
    "    img = cv2.imread(frame_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img / 255.0\n",
    "    images.append(img)\n",
    "    labels.append(label)\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e73238",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(label_mapping), activation='softmax') \n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dbf5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory_path = r'C:\\Users\\aqsa\\Downloads\\WORDS\\urdu'\n",
    "data = []\n",
    "subdirectories = [aqsa for aqsa in os.listdir(base_directory_path) if os.path.isdir(os.path.join(base_directory_path, aqsa))]\n",
    "label_mapping = {name: idx for idx, name in enumerate(subdirectories)}\n",
    "for subdir in subdirectories:\n",
    "    subdir_path = os.path.join(base_directory_path, subdir)\n",
    "    for file in os.listdir(subdir_path):\n",
    "        if file.endswith('.mp4'):\n",
    "            video_path = os.path.join(subdir_path, file)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            frame_count = 0\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                if frame_count % 30 == 0:\n",
    "                    resized_frame = cv2.resize(frame, (224, 224))  \n",
    "                    data.append((resized_frame, label_mapping[subdir]))\n",
    "                frame_count += 1\n",
    "            cap.release()\n",
    "features, labels = zip(*data)\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(subdirectories), activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf13701",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b011ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))  # InceptionV3 uses 299x299 inputs\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x) \n",
    "predictions = Dense(len(subdirectories), activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,  \n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=32)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "for layer in base_model.layers[:249]: \n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,  \n",
    "    validation_data=val_generator\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
