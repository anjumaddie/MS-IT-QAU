
# Urdu Sign Language Recognition

## Description
This project aims to recognize Urdu sign language using deep learning techniques. Utilizing TensorFlow and OpenCV, the project involves processing video files (.mov format) containing sign language gestures and translating these gestures into understandable Urdu text or speech.

## Installation

To set up this project, follow these steps:

1. Clone the repository to your local machine.
2. Ensure you have Python installed. This project was developed using Python 3.8.
3. Install the required dependencies:
```bash
pip install tensorflow opencv-python opencv-python-headless ffmpeg-python torch
```

## Usage

To use this project:

1. Place your dataset of .mov files in the designated dataset directory.
2. Run the Jupyter Notebook `Urdu_Sign_Language.ipynb` to train the model or make predictions.
3. Follow the steps within the notebook for training or inference.

## Features

- Training deep learning models using InceptionV3.
- Processing video data with OpenCV.
- Recognizing and interpreting sign language gestures.

## Contributing

Contributions are welcome! If you have suggestions or want to improve the project, please feel free to contribute. You can submit pull requests or open issues to discuss potential changes or additions.

## License

This project is open-source and available under the [MIT License](LICENSE).

## Credits

This project was inspired by the need to improve communication accessibility for the Urdu-speaking deaf community. Special thanks to all contributors and the open-source community for providing the tools and libraries used in this project.
